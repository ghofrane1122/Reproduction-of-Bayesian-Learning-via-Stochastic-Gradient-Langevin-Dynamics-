{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c032efd",
   "metadata": {},
   "source": [
    "# Section 5.2 - Reproduction using SGLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe59cc",
   "metadata": {
    "id": "defe59cc"
   },
   "source": [
    "# Bayesian Logistic Regression with SGLD\n",
    "This notebook reproduces the logistic regression experiment from the paper using SGLD on the a9a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f599489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Dataset download & preparation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import urllib.request\n",
    "import os\n",
    "import scipy.special\n",
    "\n",
    "# Download a9a dataset if not already present\n",
    "url = \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a9a\"\n",
    "filename = \"a9a\"\n",
    "if not os.path.exists(filename):\n",
    "    print(\"Downloading dataset...\")\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_svmlight_file(filename)\n",
    "X = X.toarray()\n",
    "y = (y > 0).astype(int) * 2 - 1  # Convert to {-1, +1}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "N, D = X_train.shape\n",
    "def sigmoid(z):\n",
    "    return scipy.special.expit(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Define the log joint probability function\n",
    "def log_joint(beta, X_batch, y_batch):\n",
    "    log_prior = -np.sum(np.abs(beta))  # Laplace prior (L1)\n",
    "    logits = y_batch * (X_batch @ beta)\n",
    "    log_lik = -np.sum(np.logaddexp(0, -logits))\n",
    "    return log_prior + log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. SGLD training on a9a dataset\n",
    "# SGLD parameters\n",
    "beta = np.zeros(D)\n",
    "steps = 10000\n",
    "batch_size = 10\n",
    "samples = []\n",
    "\n",
    "for t in range(steps):\n",
    "    idx = np.random.choice(N, batch_size, replace=False)\n",
    "    X_batch = X_train[idx]\n",
    "    y_batch = y_train[idx]\n",
    "\n",
    "    pred = sigmoid(y_batch * X_batch.dot(beta))\n",
    "    grad_lik = ((1 - pred) * y_batch)[:, None] * X_batch\n",
    "    grad_prior = -np.sign(beta)\n",
    "    grad = grad_prior + N / batch_size * grad_lik.mean(axis=0)\n",
    "\n",
    "    eps = 0.01 * (1 + t) ** -0.55\n",
    "    beta += 0.5 * eps * grad + np.sqrt(eps) * np.random.randn(D)\n",
    "    samples.append(beta.copy())\n",
    "\n",
    "samples = np.array(samples[-1000:]) #keep last 1000\n",
    "beta_mean = samples.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ff0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Test accuracy evaluation\n",
    "pred_test = np.sign(X_test.dot(beta_mean))\n",
    "acc = accuracy_score(y_test, pred_test)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Posterior mean & std summaries\n",
    "posterior_mean = samples.mean(axis=0)\n",
    "posterior_std = samples.std(axis=0)\n",
    "print(\"Posterior mean (first 5):\", posterior_mean[:5])\n",
    "print(\"Posterior std (first 5):\", posterior_std[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dd999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Trace plots for 5 weights\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):\n",
    "    plt.plot([s[i] for s in samples], label=f\"$\\\\beta_{i}$\")\n",
    "plt.title(\"Trace Plot of First 5 Coefficients\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Coefficient Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c28430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Accuracy curve across iterations\n",
    "accs = []\n",
    "for beta_i in samples:\n",
    "    pred = np.sign(X_test.dot(beta_i))\n",
    "    accs.append(accuracy_score(y_test, pred))\n",
    "\n",
    "plt.plot(accs)\n",
    "plt.title(\"Test Accuracy over SGLD Iterations\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68351d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Posterior histograms of most uncertain Î²\n",
    "top5 = np.argsort(-posterior_std)[:5]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, idx in enumerate(top5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    sns.histplot(samples[:, idx], bins=30, kde=True)\n",
    "    plt.title(f\"$\\\\beta_{{{idx}}}$\")\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Posterior Distributions of Most Uncertain Coefficients\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. AUC and Confusion Matrix for final predictions\n",
    "probs = sigmoid(X_test.dot(beta_mean))\n",
    "preds = np.sign(probs - 0.5)\n",
    "auc = roc_auc_score((y_test + 1) // 2, probs)\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2542b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Perform multiple runs (e.g., 10), track log joint probability and test accuracy\n",
    "num_runs = 10\n",
    "steps = 1000\n",
    "batch_size = 10\n",
    "\n",
    "acc_runs = np.zeros((num_runs, steps))\n",
    "logp_runs = np.zeros((num_runs, steps))\n",
    "\n",
    "for run in range(num_runs):\n",
    "    np.random.seed(run)\n",
    "    beta = np.zeros(D)\n",
    "    acc_list = []\n",
    "    logp_list = []\n",
    "    for t in range(steps):\n",
    "        idx = np.random.choice(N, batch_size, replace=False)\n",
    "        X_batch = X_train[idx]\n",
    "        y_batch = y_train[idx]\n",
    "        pred = sigmoid(y_batch * X_batch.dot(beta))\n",
    "        grad_lik = ((1 - pred) * y_batch)[:, None] * X_batch\n",
    "        grad_prior = -np.sign(beta)\n",
    "        grad = grad_prior + N / batch_size * grad_lik.mean(axis=0)\n",
    "        eps = 0.01 * (1 + t) ** -0.55\n",
    "        beta += 0.5 * eps * grad + np.sqrt(eps) * np.random.randn(D)\n",
    "        logp_list.append(log_joint(beta, X_train, y_train))\n",
    "        acc_list.append(accuracy_score(y_test, np.sign(X_test @ beta)))\n",
    "    acc_runs[run] = acc_list\n",
    "    logp_runs[run] = logp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b73147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. Plot the results\n",
    "x = np.arange(steps)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "mean_logp = logp_runs.mean(axis=0)\n",
    "std_logp = logp_runs.std(axis=0)\n",
    "plt.plot(x, mean_logp, label='Mean log joint')\n",
    "plt.fill_between(x, mean_logp - std_logp, mean_logp + std_logp, alpha=0.2)\n",
    "plt.title(\"Log Joint Probability\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Log Joint\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "mean_acc = acc_runs.mean(axis=0)\n",
    "std_acc = acc_runs.std(axis=0)\n",
    "plt.plot(x, mean_acc, label='Mean accuracy')\n",
    "plt.fill_between(x, mean_acc - std_acc, mean_acc + std_acc, alpha=0.2)\n",
    "plt.title(\"Accuracy on Test Set\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
